{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bd4e79-105d-4d28-b0e1-b5055aaa5dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run after environment reset\n",
    "\n",
    "import random\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sigmoid activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# Softmax for output layer\n",
    "def softmax(x):\n",
    "    e_x = [math.exp(i) for i in x]\n",
    "    sum_e_x = sum(e_x)\n",
    "    return [i / sum_e_x for i in e_x]\n",
    "\n",
    "# Cross-entropy loss\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    return -sum([y_true[i] * math.log(y_pred[i] + 1e-15) for i in range(len(y_true))])\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# One-hot encode\n",
    "def one_hot(label):\n",
    "    vec = [0, 0, 0]\n",
    "    vec[label] = 1\n",
    "    return vec\n",
    "\n",
    "# Load and preprocess data\n",
    "iris = load_iris()\n",
    "X = iris.data.tolist()\n",
    "y = [one_hot(label) for label in iris.target]\n",
    "\n",
    "# Normalize features\n",
    "for i in range(4):\n",
    "    col = [x[i] for x in X]\n",
    "    min_val, max_val = min(col), max(col)\n",
    "    for x in X:\n",
    "        x[i] = (x[i] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Network parameters\n",
    "input_size = 4\n",
    "hidden_size = 6\n",
    "output_size = 3\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "W1 = [[random.uniform(-1, 1) for _ in range(hidden_size)] for _ in range(input_size)]\n",
    "b1 = [random.uniform(-1, 1) for _ in range(hidden_size)]\n",
    "W2 = [[random.uniform(-1, 1) for _ in range(output_size)] for _ in range(hidden_size)]\n",
    "b2 = [random.uniform(-1, 1) for _ in range(output_size)]\n",
    "\n",
    "# Training\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x, y_true in zip(X_train, y_train):\n",
    "        # Forward pass\n",
    "        z1 = [sum(x[i] * W1[i][j] for i in range(input_size)) + b1[j] for j in range(hidden_size)]\n",
    "        a1 = [sigmoid(z) for z in z1]\n",
    "        z2 = [sum(a1[i] * W2[i][j] for i in range(hidden_size)) + b2[j] for j in range(output_size)]\n",
    "        y_pred = softmax(z2)\n",
    "        \n",
    "        # Loss\n",
    "        loss = cross_entropy(y_true, y_pred)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backward pass\n",
    "        dL_dz2 = [y_pred[i] - y_true[i] for i in range(output_size)]\n",
    "        dL_dW2 = [[dL_dz2[j] * a1[i] for j in range(output_size)] for i in range(hidden_size)]\n",
    "        dL_db2 = dL_dz2[:]\n",
    "\n",
    "        dL_da1 = [sum(W2[i][j] * dL_dz2[j] for j in range(output_size)) for i in range(hidden_size)]\n",
    "        dL_dz1 = [dL_da1[i] * sigmoid_derivative(a1[i]) for i in range(hidden_size)]\n",
    "        dL_dW1 = [[dL_dz1[j] * x[i] for j in range(hidden_size)] for i in range(input_size)]\n",
    "        dL_db1 = dL_dz1[:]\n",
    "\n",
    "        # Update weights and biases\n",
    "        for i in range(input_size):\n",
    "            for j in range(hidden_size):\n",
    "                W1[i][j] -= lr * dL_dW1[i][j]\n",
    "        for j in range(hidden_size):\n",
    "            b1[j] -= lr * dL_db1[j]\n",
    "        for i in range(hidden_size):\n",
    "            for j in range(output_size):\n",
    "                W2[i][j] -= lr * dL_dW2[i][j]\n",
    "        for j in range(output_size):\n",
    "            b2[j] -= lr * dL_db2[j]\n",
    "\n",
    "    losses.append(total_loss / len(X_train))\n",
    "\n",
    "# Test accuracy\n",
    "correct = 0\n",
    "for x, y_true in zip(X_test, y_test):\n",
    "    z1 = [sum(x[i] * W1[i][j] for i in range(input_size)) + b1[j] for j in range(hidden_size)]\n",
    "    a1 = [sigmoid(z) for z in z1]\n",
    "    z2 = [sum(a1[i] * W2[i][j] for i in range(hidden_size)) + b2[j] for j in range(output_size)]\n",
    "    y_pred = softmax(z2)\n",
    "    if y_pred.index(max(y_pred)) == y_true.index(max(y_true)):\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(X_test)\n",
    "losses, accuracy, W1, b1, W2, b2[:3]  # Output essential results for review\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37c5d6-a359-4b44-aa3e-4846559c391b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
